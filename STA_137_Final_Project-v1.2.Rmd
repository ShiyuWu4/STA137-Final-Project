---
title: "STA 137 Final Project"
author: 'Zhuorui He, Shiyu Wu, Sulei Wang, Zhan Shi'
date: "2024-03-12"
output:
  pdf_document:
    toc: true
  html_document:
    df_print: paged
    fig_caption: true
    number_section: false
    toc: true
    toc_float:
      collapsed: false
    fig caption: true
---

# Introduction

This study examines the annual exports data of the Central African Republic, represented as a percentage of its total GDP from 1960 to 2017. Tackling real-world datasets often involves navigating their inherent complexity, as they seldom present themselves in a straightforward manner. The methodology employed here includes applying decomposition and transformations to facilitate more effective analysis, identifying the optimal ARIMA parameters, and performing residual diagnostics to ensure model reliability. The ultimate goal is to develop an ARIMA model capable of forecasting future exports with a reasonable degree of precision.

# Background

The Central African Republic (CAR), a landlocked nation at Africa's heart, ranked 183rd globally in exports in 2022 per the Observatory of Economic Complexity (OEC). Its economy, rich in natural resources, focuses on agriculture, services, and exporting minerals, oil, timber, and agricultural products, with gold and diamonds among its top exports. Despite agriculture being pivotal, its contribution to exports is lesser. From 1960 to 2017, export volumes rose, but their GDP percentage has been declining since 1968. Major importers include the UAE, Italy, Pakistan, China, and France.

However, CAR faces challenges like political instability, violence, and inadequate resource management, hindering sustainable growth and global market competitiveness. Reliance on international aid is critical due to slow growth and a rising population, with poverty affecting 65.7% of the populace by 2021.

# Exploratory Data Analysis

```{r,include=FALSE}
# include=false will not performance our codes and results in the html file; echo=false will only show our outputs such as tables and plots
# import libraries and data here

library(ggplot2)
library(dplyr)
library(naniar)
library(astsa)
library(forecast)
library(TTR)
library(KernSmooth)
library(tseries)
load("finalproject.Rdata")
Exports<-ts(finalPro_data$Exports,start = 1960)
```

## Data Description

This dataset, sourced from the World Bank, encompasses detailed yearly data on the Gross Domestic Product (GDP), imports, and exports as a percentage of total GDP, population figures, and the GDP growth of the Central African Republic from 1960 to 2017. The focal point of our report is the Exports data. In this dataset, exports are measured as a percentage of GDP, indicating the total value of the country's exports of goods and services in relation to the size of its Gross Domestic Product. Figure 1 provides a compelling overview of the country's economic trends over the past decades.
![Figure 1. Time series of Gross Domestic Product (GDP), Growth rate, Consumer Price Index (CPI), Imports, Exports and Population for Central African Republic.
](Figure1.jpg)

## Missing Value Plots
Upon examining the dataset for missing values (Figure 2), it was found that the Exports data is free from any gaps, affirming the dataset's completeness and its suitability for conducting time series model analyses focused on Exports.

```{r}
gg_miss_var(finalPro_data)+
  labs(caption = "Figure 2: Missing Plot")+
  theme(plot.caption = element_text(size = 16,hjust=0.5))
```

## Visualization
The preliminary analysis commenced with an examination of the time series data for Exports. A subtle downward trend observed in exports, as illustrated in Figure 3, suggests the presence of a non-constant mean, indicating that the time series is non-stationary.
Further investigation was conducted on the dataset's Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF). These analyses are crucial for understanding the direct influence of past data points on future values and for determining the appropriate order of the time series model (refer to Figure 4). 

```{r}
# Plot the Export as time series data
ts.plot(Exports,main = "Time series data")
acf2(Exports,max.lag=30)
```

# Inferential Analysis

## ADF and KPSS Tests for Stationary

To evaluate the stationarity of the dataset, we applied two distinct methods: the Augmented Dickey-Fuller (ADF) test and the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test, both set at a significance level of 0.05. The ADF test deems a time series as stationary if the p-values are less than 0.05, whereas the KPSS test considers a time series stationary if the p-values exceed 0.05. Results from both tests led to the rejection of the hypothesis that the time series is stationary, confirming that the dataset is indeed non-stationary. Consequently, further measures are required to achieve stationarity for effective analysis and prediction purposes.

```{r}
sig_value <- 0.05 #significant value of test
# ADF: if p < sig, stationary
adf.test(Exports)$p.value
#KPSS: if p > sig, stationary
kpss.test(Exports)$p.value

# Both tests indicate non-stationary.
```

## Decomposition

To address the non-stationarity of the dataset, four different methods were employed to detrend the data, aiming to isolate a suitable residual component. The initial approach involved Kernel smoothing, a technique utilized to eliminate the overarching decreasing trend observed over time. This process was intended to distill the data down to its cyclical trend component, as depicted in Figures 5 and 6. The goal was to refine the data in such a way that the remaining variability could be attributed primarily to cyclical fluctuations, thereby facilitating a more focused analysis of the time series.

```{r}
#Try kernal smoothing for trend
kernel.type <- "gaussian"
bandwidth <- dpill(time(Exports), Exports)
smoothed_values <- ksmooth(x=time(Exports),y=Exports,kernel='normal',bandwidth = bandwidth,n.points = length(Exports))

plot(Exports,col='red',main="Original Export Data and Trend")
lines(smoothed_values$x, smoothed_values$y,col='blue')
legend("topright", legend=c("Original", "Trend"), col=c("red", "blue"), pch=c(19, 17))

```

```{r}
# Remove the Trend-cycle effect
Exports.noTrend <- Exports - smoothed_values$y
plot(Exports.noTrend,main='Export Data After Removing Trend')
```

To delve deeper into the model exploration, calculations of the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) were conducted. The ACF revealed a very strong correlation at a lag of 1, while the PACF displayed two pronounced correlations at lags 1 and 2. These findings suggest the potential suitability of AR(2) and MA(1) models for the de-trended data.
```{r}
acf2(Exports.noTrend,max.lag= 30)

#adf and kpss tests
adf.test(Exports.noTrend)
kpss.test(Exports.noTrend)

# Stationary now, indicating a AR(2) MA(1) possibly. Already stationary, no need for differential.

```

## First-order Difference
Another transformation attempt was made using the first-order difference, which similarly indicated the appropriateness of an AR(2), MA(1) model for the dataset. Despite this, the first-order difference transformation failed to pass the ADF test, indicating that it did not achieve stationarity. Given this outcome, the decision was made to abandon the first-order difference approach.
```{r}
# Take the 1st-order difference and test if the data is stationary
Exports.diff<-diff(Exports)
acf2(Exports.diff,max.lag= 30)

adf.test(Exports.diff)
kpss.test(Exports.diff)

#suggesting AR(2), MA(1), but does not pass ADF test.
```

## Box-Cox Transformation
The application of both Box-Cox Transformation and Log Transformation was explored to address the non-stationary nature of the time series. However, subsequent analysis revealed that both transformations resulted in time series that remained non-stationary, as evidenced in Figure 8. Following the application of differencing to these transformed datasets, the ACF and PACF analyses of the differences suggested characteristics akin to a random series, resembling white noise. Consequently, due to these outcomes, both the Box-Cox and Log Transformations were deemed unsuitable for further consideration and were thus discarded from the analysis.

```{r}
# Box-Cox transformation
lambda<-BoxCox.lambda(Exports)
Exports.Box<-BoxCox(Exports,lambda)
acf2(Exports.Box,max.lag = 30)
#ts.plot(Exports.Box,main = "Time series data after Box-Cox")
acf2(diff(Exports.Box),max.lag = 30)

# suggesting white noise, so discard this transformation
```

## Log Transformation
```{r}

# Take the 1st-order difference and test if the data is stationary
Exports.log<-log(Exports)
acf2(Exports.log,max.lag= 30)
acf2((diff(Exports.log)),max.lag= 30)

#suggesting white noise, so discard this transformation
```
After thorough comparison and careful consideration, the decision was made to select the detrending method as the preferred approach for preparing our data for model fitting in the subsequent phase of analysis.

## ARIMA Model
(Post the formula here by using LaTeX)

For the ARIMA(q,d,p) model
$$
X_t'=\sum_{i=1}^p\alpha_pX_{t-p}'+\sum_{i=1}^q\theta_q\omega_{t-q}
$$
where $X_t'=(1-B)^dX_t$
The model exhibits an order in the form of (p, d, q) where:
P =The order of the Auto Regressive Model
d = the order of differencing
Q = The order of the Moving Average 
Following the detrending of the Exports dataset, the next step involved establishing the ARIMA model. To accurately determine the optimal parameters for the ARIMA(p,d,q) model, an automatic selection process was employed. This method suggested ARIMA(2,0,1) as the most fitting model for our data.
```{r}
# Auto select the best p,d,q combination for ARIMA(p,d,q)
Exports.noTrend.auto <- auto.arima(Exports.noTrend)
summary(Exports.noTrend.auto)
```


## Model Comparison

```{r}
# Use SARIMA to determent the performance, acf of residual all need to be in range, p-value needs to be greater than 0.1, QQ lines close to the line.
# ARIMA(2,0,1)
fit1<-sarima(Exports.noTrend, 2,0,1, no.constant=TRUE)
summary(fit1)

# MSE is a standard to evaluate the model. The smaller is the better.
MSE1<-sum(fit1$fit$residuals)/58
print(paste(c("Training MSE:",MSE1)))
```
Due to the Q-Q plot, the ARIMA Model is heavy-tailed slightly.

```{r}
# ARIMA(2,1,1)
fit2<-sarima(Exports.noTrend, 2,1,1, no.constant=TRUE)
summary(fit2)

# MSE
MSE2<-sum(fit2$fit$residuals)/58
print(paste(c("Training MSE:",MSE2)))
```

```{r}
#ARIMA(3,0,1)
fit3<-sarima(Exports.noTrend, 3,0,1, no.constant=TRUE)
summary(fit3)

# MSE 
MSE3<-sum(fit3$fit$residuals)/58
print(paste(c("Training MSE:",MSE3)))
```


# Diagnosis


# Forecast

After comparing models and conducting diagnostics, ARIMA(2,0,1) with detrended data was identified as the optimal choice. The model formula is
$$
(1-\phi_1B-\phi_2B^2)x_t=(1+B)w_t
$$
Utilizing this model, we forecasted the white noise in exports for the next six years with a significance level $\alpha=0.05$.

```{r}
sarima.for(Exports,n.ahead = 6,p=2,d=0,q=1)
forecast(arima(Exports.noTrend,c(2,0,1)))
autoplot(forecast(arima(Exports.noTrend,c(2,0,1))))
```
The forecast depicted focuses solely on the random white noise component of exports over the next six years, not the actual future exports. To accurately forecast total exports, a linear fit and prediction of the trend using a separate linear model would be necessary. However, this paper concentrates primarily on analyzing the random noise within the time series, not on predicting the trend.

# Discussion


## Conclusion

\newpage

# Reference 

(If any)

# Code Appendix

```{r getlabels2, echo = FALSE}
labs = knitr::all_labels()
labs = labs[!labs %in% c("setup","getlabels1","getlabels2","allcode")]
```

```{r allcode, ref.label = labs, eval = FALSE}
```
