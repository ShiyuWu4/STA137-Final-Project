---
title: "STA 137 Final Project"
author: 'Zhuorui He, Shiyu Wu, Sulei Wang, Zhan Shi'
date: "2024-03-12"
output:
  pdf_document:
    toc: true
  html_document:
    df_print: paged
    fig_caption: true
    number_section: true
    toc: true
    toc_float:
      collapsed: false
    fig caption: true
---

```{r setup}
knitr::opts_chunk$set(
  include = FALSE
)
```

# Introduction

This study examines the annual exports data of the Central African Republic, represented as a percentage of its total GDP from 1960 to 2017. Tackling real-world datasets often involves navigating their inherent complexity, as they seldom present themselves in a straightforward manner. The methodology employed here includes applying decomposition and transformations to facilitate more effective analysis, identifying the optimal ARIMA parameters, and performing residual diagnostics to ensure model reliability. The ultimate goal is to develop an ARIMA model capable of forecasting future exports with a reasonable degree of precision.

# Background

The Central African Republic (CAR), a landlocked nation at Africa's heart, ranked 183rd globally in exports in 2022 per the Observatory of Economic Complexity (OEC). Its economy, rich in natural resources, focuses on agriculture, services, and exporting minerals, oil, timber, and agricultural products, with gold and diamonds among its top exports. Despite agriculture being pivotal, its contribution to exports is lesser. From 1960 to 2017, export volumes rose, but their GDP percentage has been declining since 1968. Major importers include the UAE, Italy, Pakistan, China, and France.

However, CAR faces challenges like political instability, violence, and inadequate resource management, hindering sustainable growth and global market competitiveness. Reliance on international aid is critical due to slow growth and a rising population, with poverty affecting 65.7% of the populace by 2021.

# Exploratory Data Analysis

```{r,include=FALSE}
# include=false will not performance our codes and results in the html file; echo=false will only show our outputs such as tables and plots
# import libraries and data here

library(ggplot2)
library(dplyr)
library(naniar)
library(astsa)
library(forecast)
library(TTR)
library(KernSmooth)
library(tseries)
load("finalproject.Rdata")
Exports<-ts(finalPro_data$Exports,start = 1960)
```

## Data Description

This dataset, sourced from the World Bank, encompasses detailed yearly data on the Gross Domestic Product (GDP), imports, and exports as a percentage of total GDP, population figures, and the GDP growth of the Central African Republic from 1960 to 2017. The focal point of our report is the Exports data. In this dataset, exports are measured as a percentage of GDP, indicating the total value of the country's exports of goods and services in relation to the size of its Gross Domestic Product. The figure below provides a compelling overview of the country's economic trends over the past decades.
![Figure 1. Time series of Gross Domestic Product (GDP), Growth rate, Consumer Price Index (CPI), Imports, Exports and Population for Central African Republic.
](Figure1.jpg)

## Visualization

The preliminary analysis commenced with an examination of the time series data for Exports. A subtle downward trend observed in exports, as illustrated in the figure below, suggests the presence of a non-constant mean, indicating that the time series is non-stationary.
Further investigation was conducted on the dataset's Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF). These analyses are crucial for understanding the direct influence of past data points on future values and for determining the appropriate order of the time series model. 

```{r,echo=FALSE}
# Plot the Export as time series data
ts.plot(Exports,main = "Time series data")
acf2(Exports,max.lag=30)
```

# Inferential Analysis

## ADF and KPSS Tests for Stationary

To numerically evaluate the stationarity of the dataset, we applied two distinct methods: the Augmented Dickey-Fuller (ADF) test and the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test, both set at a significance level of 0.05. The ADF test deems a time series as stationary if the p-values are less than 0.05, whereas the KPSS test considers a time series stationary if the p-values exceed 0.05. Results from both tests led to the rejection of the hypothesis that the time series is stationary, confirming that the dataset is indeed non-stationary.
All our models are predicated on the foundation of stationary data, which imparts numerous characteristics and properties crucial for prediction. Consequently, transforming the data into a time-independent format is essential to harness these advantages effectively.

```{r,echo=FALSE,warning=FALSE}
sig_value <- 0.05 #significant value of test
# ADF: if p < sig, stationary
adf.test(Exports)$p.value
#KPSS: if p > sig, stationary
kpss.test(Exports)$p.value

# Both tests indicate non-stationary.
```

## Decomposition

To address the non-stationarity of the dataset, four different methods were employed to detrend the data, aiming to isolate a suitable residual component. The initial approach involved Kernel smoothing, a technique utilized to eliminate the overarching decreasing trend observed over time. This process was intended to distill the data down to its cyclical trend component, as depicted in figures below. The goal was to refine the data in such a way that the remaining variability could be attributed primarily to cyclical fluctuations, thereby facilitating a more focused analysis of the time series.

```{r,echo=FALSE}
#Try kernal smoothing for trend
kernel.type <- "gaussian"
bandwidth <- dpill(time(Exports), Exports)
smoothed_values <- ksmooth(x=time(Exports),y=Exports,kernel='normal',bandwidth = bandwidth,n.points = length(Exports))

plot(Exports,col='red',main="Original Export Data and Trend")
lines(smoothed_values$x, smoothed_values$y,col='blue')
legend("topright", legend=c("Original", "Trend"), col=c("red", "blue"), pch=c(19, 17))

```

```{r,echo=FALSE,warning=FALSE}
# Remove the Trend-cycle effect
Exports.noTrend <- Exports - smoothed_values$y
plot(Exports.noTrend,main='Export Data After Removing Trend')
```

To delve deeper into the model exploration, calculations of the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) were conducted. ACF and PACF are instrumental in identifying the lags with significant impact on the current value. They play a crucial role in delineating the pattern of the time series, thereby aiding in the selection of an appropriate model. The ACF revealed a very strong correlation at a lag of 1, while the PACF displayed two pronounced correlations at lags 1 and 2. These findings suggest the potential suitability of AR(2) and MA(1) models for the de-trended data.

```{r,echo=FALSE,results = FALSE,warning=FALSE}
# Plot ACF and PACF
acf2(Exports.noTrend,max.lag= 30,main = "ACF and PACF for data without trend")
```

```{r,echo=FALSE,warning=FALSE}
#adf and kpss tests
adf.test(Exports.noTrend)
kpss.test(Exports.noTrend)

# Stationary now, indicating a AR(2) MA(1) possibly. Already stationary, no need for differential.

```

## First-order Difference

Another transformation attempt was made using the first-order difference, which similarly indicated the appropriateness of an AR(2), MA(1) model for the dataset. Despite this, the first-order difference transformation failed to pass the ADF test, indicating that it did not achieve stationarity. Given this outcome, the decision was made to abandon the first-order difference approach.

```{r,echo=FALSE,result=FALSE,warning=FALSE}
# Take the 1st-order difference and test if the data is stationary
Exports.diff<-diff(Exports)
acf2(Exports.diff,max.lag= 30)
```
```{r,echo=FALSE}
adf.test(Exports.diff)
kpss.test(Exports.diff)

#suggesting AR(2), MA(1), but does not pass ADF test.
```

## Box-Cox Transformation

The application of both Box-Cox Transformation and Log Transformation was explored to address the non-stationary nature of the time series. However, subsequent analysis revealed that both transformations resulted in time series that remained non-stationary, as evidenced in figure below. Following the application of differencing to these transformed datasets, the ACF and PACF analyses of the differences suggested characteristics akin to a random series, resembling white noise. Consequently, due to these outcomes, both the Box-Cox and Log Transformations were deemed unsuitable for further consideration and were thus discarded from the analysis.

```{r,echo=FALSE,results=FALSE}
# Box-Cox transformation
lambda<-BoxCox.lambda(Exports)
Exports.Box<-BoxCox(Exports,lambda)
acf2(Exports.Box,max.lag = 30)
#ts.plot(Exports.Box,main = "Time series data after Box-Cox")
acf2(diff(Exports.Box),max.lag = 30)

# suggesting white noise, so discard this transformation
```

## Log Transformation

```{r,echo=FALSE,results=FALSE}
# Take the 1st-order difference and test if the data is stationary
Exports.log<-log(Exports)
acf2(Exports.log,max.lag= 30)
acf2((diff(Exports.log)),max.lag= 30)

#suggesting white noise, so discard this transformation
```

After thorough comparison and careful consideration, the decision was made to select the detrending method as the preferred approach for preparing our data for model fitting in the subsequent phase of analysis.

## ARIMA Model

For the ARIMA(q,d,p) model
$$
X_t'=\sum_{i=1}^p\alpha_pX_{t-p}'+\sum_{i=1}^q\theta_q\omega_{t-q}
$$

where $X_t'=(1-B)^dX_t$
The model exhibits an order in the form of (p, d, q) where:
P =The order of the Auto Regressive Model
d = the order of differencing
Q = The order of the Moving Average 
Following the detrending of the Exports dataset, the next step involved establishing the ARIMA model. To accurately determine the optimal parameters for the ARIMA(p,d,q) model, an automatic selection process was employed. This method suggested ARIMA(2,0,1) as the most fitting model for our data.

```{r,echo=FALSE}
# Auto select the best p,d,q combination for ARIMA(p,d,q)
Exports.noTrend.auto <- auto.arima(Exports.noTrend)
summary(Exports.noTrend.auto)
```


### Model Comparison

To discern the most effective model, Mean Squared Error (MSE) and Akaike Information Criterion (AIC) were employed as the primary metrics. MSE helps estimate the average of squared errors during model training, while AIC assesses both the prediction error and the extent of information loss during model fitting.

$$
MSE=\frac{\sum(Residuals)^2}{n}
$$
$$
AIC=n\times ln(\frac{\sum(Residuals)^2}{n})+2k
$$
where n is the number of observations in the model, and k is the number of parameters.

The SARIMA model was utilized for evaluation, showing that the ACF of residuals mostly fell within the expected confidence range, with the Q-Q plot revealing a good alignment of most points along the fit line, albeit with some evidence of heavy tails. Comparisons were made between ARIMA(2,1,1) and ARIMA(3,0,1), against the backdrop of ARIMA(2,0,1). While ARIMA(2,1,1) exhibited a lower MSE of 0.0128 compared to ARIMA(3,0,1)'s MSE of 0.0735 and ARIMA(2,0,1)'s MSE of 0.00430, it was disqualified due to its p-values falling below the significance line for lags less than 5, indicating autocorrelation and dependency within white noise, rendering it suboptimal.

Despite ARIMA(3,0,1) presenting a slightly better AIC of 2.544 against ARIMA(2,0,1)â€™s AIC of 2.613, the minimal difference and the preference for simplicity guided the choice towards ARIMA(2,0,1) for prediction purposes, with the specific equation provided in the following segment.

```{r,echo=FALSE}
# Use SARIMA to determent the performance, acf of residual all need to be in range, p-value needs to be greater than 0.1, QQ lines close to the line.
# ARIMA(2,0,1)
fit1<-sarima(Exports.noTrend, 2,0,1, no.constant=TRUE)
summary(fit1)

# MSE is a standard to evaluate the model. The smaller is the better.
MSE1<-sum(fit1$fit$residuals)/58
print(paste(c("Training MSE:",MSE1)))
```
```{r}
# ARIMA(2,1,1)
fit2<-sarima(Exports.noTrend, 2,1,1, no.constant=TRUE)
summary(fit2)

# MSE
MSE2<-sum(fit2$fit$residuals)/58
print(paste(c("Training MSE:",MSE2)))
```

```{r,echo=FALSE}
#ARIMA(3,0,1)
fit3<-sarima(Exports.noTrend, 3,0,1, no.constant=TRUE)
summary(fit3)

# MSE 
MSE3<-sum(fit3$fit$residuals)/58
print(paste(c("Training MSE:",MSE3)))
```



## Forecast

After comparing models and conducting diagnostics, ARIMA(2,0,1) with detrended data was identified as the optimal choice. The model formula is
$$
(1-\phi_1B-\phi_2B^2)x_t=(1+B)w_t
$$

Utilizing this model, we forecasted the white noise in exports for the next six years with a significance level $\alpha=0.05$.

```{r,echo=FALSE}
sarima.for(Exports,n.ahead = 6,p=2,d=0,q=1)
forecast(arima(Exports.noTrend,c(2,0,1)))
autoplot(forecast(arima(Exports.noTrend,c(2,0,1))))
```

The forecast depicted focuses solely on the random white noise component of exports over the next six years, not the actual future exports. To accurately forecast total exports, a linear fit and prediction of the trend using a separate linear model would be necessary. However, this paper concentrates primarily on analyzing the random noise within the time series, not on predicting the trend.



# Conclusion

In this project, detrending the data was chosen as the necessary step to adhere to the stationary assumption and reduce errors, leading to the establishment of an ARIMA(2,0,1) model. However, the forecast process encounters a limitation due to its inability to predict future trends, offering only a 95% confidence interval for predictions that exclude any trend component. This constitutes a significant constraint of the study.

Looking ahead, to address this limitation and enhance the project, an initial step could involve identifying suitable functions or distributions to estimate the trend, which would allow for more comprehensive confidence intervals that incorporate the trend. Additionally, the introduction of more data and the exploration of alternative modeling approaches, such as the Long Short-Term Memory (LSTM) model, could offer improved outcomes that include trend analysis, thus broadening the scope and applicability of the findings.

\newpage

# Reference 

(n.d.). Exports of goods and services (% of GDP) - Central African Republic. THE WORLD BANK. https://data.worldbank.org/indicator/NE.EXP.GNFS.ZS?locations=CF

# Code Appendix

```{r getlabels2, echo = FALSE}
labs = knitr::all_labels()
labs = labs[!labs %in% c("setup","getlabels1","getlabels2","allcode")]
```

```{r allcode, ref.label = labs, eval = FALSE}
```
