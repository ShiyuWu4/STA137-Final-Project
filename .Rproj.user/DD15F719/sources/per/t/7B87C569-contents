---
title: "STA 137 Final Project"
author: '[Write your name here]'
date: "2024-03-12"
output: 
  html_document:
    df_print: paged
    fig_caption: yes
    number_section: No
    toc: true
    toc_float:
      collapsed: false
    fig caption: true
---

# Introduction

Write down our question of interest and motivations here. It should not be too long.

# Background

Google related background on the Central African Republic Exports
data and summarize some useful information

What's the unit of export, million dollars?

# Exploratory Data Analysis

```{r,include=FALSE}
# include=false will not performance our codes and results in the html file; echo=false will only show our outputs such as tables and plots
# import libraries and data here

library(ggplot2)
library(dplyr)
library(naniar)
library(astsa)
library(forecast)
library(TTR)
library(KernSmooth)
library(tseries)
load("finalproject.Rdata")
Exports<-ts(finalPro_data$Exports,start = 1960)
```

## Data Description

## Missing Value Plots

```{r}
gg_miss_var(finalPro_data)+
  labs(caption = "Figure 1: Missing Plot")+
  theme(plot.caption = element_text(size = 16,hjust=0.5))
```

## Visualization

```{r}
# Plot the Export as time series data
ts.plot(Exports,main = "Time series data")
acf2(Exports,max.lag=30)
```

[Explanation]

If we want to have more texts and plots, we can give all variable a plot...

# Inferential Analysis

## ADF and KPSS Tests for Stationary

```{r}
sig_value <- 0.05 #significant value of test
# ADF: if p < sig, stationary
adf.test(Exports)$p.value
#KPSS: if p > sig, stationary
kpss.test(Exports)$p.value

# Both tests indicate non-stationary.
```

## Decomposition

Two methods of smoothing, Kernel and symmetric moving average(SMA). Determine the effect of both and choose one.

```{r}
#Try kernal smoothing for trend
kernel.type <- "gaussian"
bandwidth <- dpill(time(Exports), Exports)
smoothed_values <- ksmooth(x=time(Exports),y=Exports,kernel='normal',bandwidth = bandwidth,n.points = length(Exports))

plot(Exports,col='red')
lines(smoothed_values$x, smoothed_values$y,col='blue')

```

[Explain why seasonal adjustment because the unit is year] [smoothing method]

```{r}
# Remove the Trend-cycle effect
Exports.noTrend <- Exports - smoothed_values$y
plot(Exports.noTrend)
```
```{r}
acf2(Exports.noTrend,max.lag= 30)

#adf and kpss tests
adf.test(Exports.noTrend)
kpss.test(Exports.noTrend)

# Stationary now, indicating a AR(2) MA(1) possibly. Already stationary, no need for differential.

```

## First-order Difference

```{r}
# Take the 1st-order difference and test if the data is stationary
Exports.diff<-diff(Exports)
acf2(Exports.diff,max.lag= 30)

#suggesting AR(2), MA(1)
```

## Box-Cox Transformation

```{r}
# Box-Cox transformation
lambda<-BoxCox.lambda(Exports)
Exports.Box<-BoxCox(Exports,lambda)
acf2(Exports.Box,max.lag = 30)
#ts.plot(Exports.Box,main = "Time series data after Box-Cox")
acf2(diff(Exports.Box),max.lag = 30)

# suggesting white noise, so discard this transformation
```

## Log Transformation
```{r}

# Take the 1st-order difference and test if the data is stationary
Exports.log<-log(Exports)
acf2(Exports.log,max.lag= 30)
acf2((diff(Exports.log)),max.lag= 30)

#suggesting white noise, so discard this transformation
```

## ARIMA Model
(Post the formula here by using LaTeX)

For the ARIMA(q,d,p) model
$$
X_t'=\sum_{i=1}^p\alpha_pX_{t-p}'+\sum_{i=1}^q\theta_qw_{t-q}
$$
where $X_t'=(1-B)^dX_t$


```{r}
# Auto select the best p,d,q combination for ARIMA(p,d,q)
Exports.noTrend.auto <- auto.arima(Exports.noTrend)
summary(Exports.noTrend.auto)

```


## Model Comparison

Since we used a first-order difference, assume the model has a constant term which betters the performance.
```{r}
# Use SARIMA to determent the performance, acf of residual all need to be in range, p-value needs to be greater than 0.1, QQ lines close to the line.
# ARIMA(2,0,1)
fit1<-sarima(Exports.noTrend, 2,0,1, no.constant=TRUE)
summary(fit1)

# MSE is a standard to evaluate the model. The smaller is the better.
MSE1<-sum(fit1$fit$residuals)/58
print(paste(c("Training MSE:",MSE1)))
```
Due to the Q-Q plot, the ARIMA Model is heavy-tailed slightly.

```{r}
# ARIMA(2,1,1)
fit2<-sarima(Exports.noTrend, 2,1,1, no.constant=TRUE)
summary(fit2)

# MSE
MSE2<-sum(fit2$fit$residuals)/58
print(paste(c("Training MSE:",MSE2)))
```

```{r}
#ARIMA(3,0,1)
fit3<-sarima(Exports.noTrend, 3,0,1, no.constant=TRUE)
summary(fit3)

# MSE 
MSE3<-sum(fit3$fit$residuals)/58
print(paste(c("Training MSE:",MSE3)))
```

# Forecast

Since we choose ARIMA(2,0,1) as our final ARIMA model, our formula for it should be
$$
(1-\phi_1B-\phi_2B^2)x_t=(1+B)w_t
$$
Set the significance level $\alpha=0.05$, our forecast for the next 6 years are shown on the plot below

```{r}
sarima.for(Exports,n.ahead = 6,p=2,d=0,q=1)
```
Explain this forecast plot.

# Discussion



\newpage

# Reference 

(If any)

# Code Appendix

```{r getlabels2, echo = FALSE}
labs = knitr::all_labels()
labs = labs[!labs %in% c("setup","getlabels1","getlabels2","allcode")]
```

```{r allcode, ref.label = labs, eval = FALSE}
```
